{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as P\n",
    "import torchvision\n",
    "\n",
    "from BigGAN import Generator, Discriminator\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "device = 'cpu'\n",
    "strict = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator saved_args is {'self': Generator(), 'G_ch': 64, 'dim_z': 128, 'bottom_width': 4, 'resolution': 128, 'G_kernel_size': 3, 'G_attn': '64', 'n_classes': 1000, 'num_G_SVs': 1, 'num_G_SV_itrs': 1, 'G_shared': True, 'shared_dim': 0, 'hier': False, 'cross_replica': False, 'mybn': False, 'G_activation': ReLU(), 'G_lr': 5e-05, 'G_B1': 0.0, 'G_B2': 0.999, 'adam_eps': 1e-08, 'BN_eps': 1e-05, 'SN_eps': 1e-12, 'G_mixed_precision': False, 'G_fp16': False, 'G_init': 'ortho', 'skip_init': False, 'no_optim': False, 'G_param': 'SN', 'norm_style': 'bn', 'kwargs': {}, '__class__': <class 'BigGAN.Generator'>}\n",
      "Adding attention layer in G at resolution 64\n",
      "Param count for Gs initialized parameters: 33550851\n",
      "/home/jjw/projects/twin-auxiliary-gan/TAC-BigGAN\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Generator:\n\tMissing key(s) in state_dict: \"shared.weight\", \"blocks.0.0.bn1.gain.u0\", \"blocks.0.0.bn1.gain.sv0\", \"blocks.0.0.bn1.bias.u0\", \"blocks.0.0.bn1.bias.sv0\", \"blocks.0.0.bn2.gain.u0\", \"blocks.0.0.bn2.gain.sv0\", \"blocks.0.0.bn2.bias.u0\", \"blocks.0.0.bn2.bias.sv0\", \"blocks.1.0.bn1.gain.u0\", \"blocks.1.0.bn1.gain.sv0\", \"blocks.1.0.bn1.bias.u0\", \"blocks.1.0.bn1.bias.sv0\", \"blocks.1.0.bn2.gain.u0\", \"blocks.1.0.bn2.gain.sv0\", \"blocks.1.0.bn2.bias.u0\", \"blocks.1.0.bn2.bias.sv0\", \"blocks.2.0.bn1.gain.u0\", \"blocks.2.0.bn1.gain.sv0\", \"blocks.2.0.bn1.bias.u0\", \"blocks.2.0.bn1.bias.sv0\", \"blocks.2.0.bn2.gain.u0\", \"blocks.2.0.bn2.gain.sv0\", \"blocks.2.0.bn2.bias.u0\", \"blocks.2.0.bn2.bias.sv0\", \"blocks.3.0.conv1.weight\", \"blocks.3.0.conv1.bias\", \"blocks.3.0.conv1.u0\", \"blocks.3.0.conv1.sv0\", \"blocks.3.0.conv2.weight\", \"blocks.3.0.conv2.bias\", \"blocks.3.0.conv2.u0\", \"blocks.3.0.conv2.sv0\", \"blocks.3.0.conv_sc.weight\", \"blocks.3.0.conv_sc.bias\", \"blocks.3.0.conv_sc.u0\", \"blocks.3.0.conv_sc.sv0\", \"blocks.3.0.bn1.stored_mean\", \"blocks.3.0.bn1.stored_var\", \"blocks.3.0.bn1.gain.weight\", \"blocks.3.0.bn1.gain.u0\", \"blocks.3.0.bn1.gain.sv0\", \"blocks.3.0.bn1.bias.weight\", \"blocks.3.0.bn1.bias.u0\", \"blocks.3.0.bn1.bias.sv0\", \"blocks.3.0.bn2.stored_mean\", \"blocks.3.0.bn2.stored_var\", \"blocks.3.0.bn2.gain.weight\", \"blocks.3.0.bn2.gain.u0\", \"blocks.3.0.bn2.gain.sv0\", \"blocks.3.0.bn2.bias.weight\", \"blocks.3.0.bn2.bias.u0\", \"blocks.3.0.bn2.bias.sv0\", \"blocks.3.1.gamma\", \"blocks.3.1.theta.weight\", \"blocks.3.1.theta.u0\", \"blocks.3.1.theta.sv0\", \"blocks.3.1.phi.weight\", \"blocks.3.1.phi.u0\", \"blocks.3.1.phi.sv0\", \"blocks.3.1.g.weight\", \"blocks.3.1.g.u0\", \"blocks.3.1.g.sv0\", \"blocks.3.1.o.weight\", \"blocks.3.1.o.u0\", \"blocks.3.1.o.sv0\", \"blocks.4.0.conv1.weight\", \"blocks.4.0.conv1.bias\", \"blocks.4.0.conv1.u0\", \"blocks.4.0.conv1.sv0\", \"blocks.4.0.conv2.weight\", \"blocks.4.0.conv2.bias\", \"blocks.4.0.conv2.u0\", \"blocks.4.0.conv2.sv0\", \"blocks.4.0.conv_sc.weight\", \"blocks.4.0.conv_sc.bias\", \"blocks.4.0.conv_sc.u0\", \"blocks.4.0.conv_sc.sv0\", \"blocks.4.0.bn1.stored_mean\", \"blocks.4.0.bn1.stored_var\", \"blocks.4.0.bn1.gain.weight\", \"blocks.4.0.bn1.gain.u0\", \"blocks.4.0.bn1.gain.sv0\", \"blocks.4.0.bn1.bias.weight\", \"blocks.4.0.bn1.bias.u0\", \"blocks.4.0.bn1.bias.sv0\", \"blocks.4.0.bn2.stored_mean\", \"blocks.4.0.bn2.stored_var\", \"blocks.4.0.bn2.gain.weight\", \"blocks.4.0.bn2.gain.u0\", \"blocks.4.0.bn2.gain.sv0\", \"blocks.4.0.bn2.bias.weight\", \"blocks.4.0.bn2.bias.u0\", \"blocks.4.0.bn2.bias.sv0\". \n\tsize mismatch for linear.weight: copying a param with shape torch.Size([4096, 128]) from checkpoint, the shape in current model is torch.Size([16384, 128]).\n\tsize mismatch for linear.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([16384]).\n\tsize mismatch for linear.u0: copying a param with shape torch.Size([1, 4096]) from checkpoint, the shape in current model is torch.Size([1, 16384]).\n\tsize mismatch for blocks.0.0.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for blocks.0.0.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.conv1.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for blocks.0.0.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for blocks.0.0.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.conv2.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for blocks.0.0.conv_sc.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for blocks.0.0.conv_sc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.conv_sc.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for blocks.0.0.bn1.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn1.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn1.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.0.0.bn1.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.0.0.bn2.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn2.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn2.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.0.0.bn2.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.1.0.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\n\tsize mismatch for blocks.1.0.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.conv1.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for blocks.1.0.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for blocks.1.0.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.conv2.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for blocks.1.0.conv_sc.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for blocks.1.0.conv_sc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.conv_sc.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for blocks.1.0.bn1.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.1.0.bn1.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.1.0.bn1.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.1.0.bn1.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.1.0.bn2.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.bn2.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.bn2.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.1.0.bn2.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for blocks.2.0.conv_sc.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for blocks.2.0.bn1.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.2.0.bn1.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.2.0.bn1.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.2.0.bn1.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.2.0.bn2.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for blocks.2.0.bn2.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for output_layer.0.gain: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.0.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.0.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.2.weight: copying a param with shape torch.Size([3, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 64, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fcdf4f1a6226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Biggan_result/weights/Twin_AC_AC_weight1.0_BigGAN_C100_seed0_Gch64_Dch64_bs100_nDs2_Glr2.0e-04_Dlr2.0e-04_Gnlrelu_Dnlrelu_GinitN02_DinitN02_ema/G_ema.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# D.load_state_dict(torch.load('../Biggan_result/weights/Twin_AC_AC_weight1.0_BigGAN_C100_seed0_Gch64_Dch64_bs100_nDs2_Glr2.0e-04_Dlr2.0e-04_Gnlrelu_Dnlrelu_GinitN02_DinitN02_ema/D.pth'), strict=strict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/postech/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Generator:\n\tMissing key(s) in state_dict: \"shared.weight\", \"blocks.0.0.bn1.gain.u0\", \"blocks.0.0.bn1.gain.sv0\", \"blocks.0.0.bn1.bias.u0\", \"blocks.0.0.bn1.bias.sv0\", \"blocks.0.0.bn2.gain.u0\", \"blocks.0.0.bn2.gain.sv0\", \"blocks.0.0.bn2.bias.u0\", \"blocks.0.0.bn2.bias.sv0\", \"blocks.1.0.bn1.gain.u0\", \"blocks.1.0.bn1.gain.sv0\", \"blocks.1.0.bn1.bias.u0\", \"blocks.1.0.bn1.bias.sv0\", \"blocks.1.0.bn2.gain.u0\", \"blocks.1.0.bn2.gain.sv0\", \"blocks.1.0.bn2.bias.u0\", \"blocks.1.0.bn2.bias.sv0\", \"blocks.2.0.bn1.gain.u0\", \"blocks.2.0.bn1.gain.sv0\", \"blocks.2.0.bn1.bias.u0\", \"blocks.2.0.bn1.bias.sv0\", \"blocks.2.0.bn2.gain.u0\", \"blocks.2.0.bn2.gain.sv0\", \"blocks.2.0.bn2.bias.u0\", \"blocks.2.0.bn2.bias.sv0\", \"blocks.3.0.conv1.weight\", \"blocks.3.0.conv1.bias\", \"blocks.3.0.conv1.u0\", \"blocks.3.0.conv1.sv0\", \"blocks.3.0.conv2.weight\", \"blocks.3.0.conv2.bias\", \"blocks.3.0.conv2.u0\", \"blocks.3.0.conv2.sv0\", \"blocks.3.0.conv_sc.weight\", \"blocks.3.0.conv_sc.bias\", \"blocks.3.0.conv_sc.u0\", \"blocks.3.0.conv_sc.sv0\", \"blocks.3.0.bn1.stored_mean\", \"blocks.3.0.bn1.stored_var\", \"blocks.3.0.bn1.gain.weight\", \"blocks.3.0.bn1.gain.u0\", \"blocks.3.0.bn1.gain.sv0\", \"blocks.3.0.bn1.bias.weight\", \"blocks.3.0.bn1.bias.u0\", \"blocks.3.0.bn1.bias.sv0\", \"blocks.3.0.bn2.stored_mean\", \"blocks.3.0.bn2.stored_var\", \"blocks.3.0.bn2.gain.weight\", \"blocks.3.0.bn2.gain.u0\", \"blocks.3.0.bn2.gain.sv0\", \"blocks.3.0.bn2.bias.weight\", \"blocks.3.0.bn2.bias.u0\", \"blocks.3.0.bn2.bias.sv0\", \"blocks.3.1.gamma\", \"blocks.3.1.theta.weight\", \"blocks.3.1.theta.u0\", \"blocks.3.1.theta.sv0\", \"blocks.3.1.phi.weight\", \"blocks.3.1.phi.u0\", \"blocks.3.1.phi.sv0\", \"blocks.3.1.g.weight\", \"blocks.3.1.g.u0\", \"blocks.3.1.g.sv0\", \"blocks.3.1.o.weight\", \"blocks.3.1.o.u0\", \"blocks.3.1.o.sv0\", \"blocks.4.0.conv1.weight\", \"blocks.4.0.conv1.bias\", \"blocks.4.0.conv1.u0\", \"blocks.4.0.conv1.sv0\", \"blocks.4.0.conv2.weight\", \"blocks.4.0.conv2.bias\", \"blocks.4.0.conv2.u0\", \"blocks.4.0.conv2.sv0\", \"blocks.4.0.conv_sc.weight\", \"blocks.4.0.conv_sc.bias\", \"blocks.4.0.conv_sc.u0\", \"blocks.4.0.conv_sc.sv0\", \"blocks.4.0.bn1.stored_mean\", \"blocks.4.0.bn1.stored_var\", \"blocks.4.0.bn1.gain.weight\", \"blocks.4.0.bn1.gain.u0\", \"blocks.4.0.bn1.gain.sv0\", \"blocks.4.0.bn1.bias.weight\", \"blocks.4.0.bn1.bias.u0\", \"blocks.4.0.bn1.bias.sv0\", \"blocks.4.0.bn2.stored_mean\", \"blocks.4.0.bn2.stored_var\", \"blocks.4.0.bn2.gain.weight\", \"blocks.4.0.bn2.gain.u0\", \"blocks.4.0.bn2.gain.sv0\", \"blocks.4.0.bn2.bias.weight\", \"blocks.4.0.bn2.bias.u0\", \"blocks.4.0.bn2.bias.sv0\". \n\tsize mismatch for linear.weight: copying a param with shape torch.Size([4096, 128]) from checkpoint, the shape in current model is torch.Size([16384, 128]).\n\tsize mismatch for linear.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([16384]).\n\tsize mismatch for linear.u0: copying a param with shape torch.Size([1, 4096]) from checkpoint, the shape in current model is torch.Size([1, 16384]).\n\tsize mismatch for blocks.0.0.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for blocks.0.0.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.conv1.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for blocks.0.0.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for blocks.0.0.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.conv2.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for blocks.0.0.conv_sc.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for blocks.0.0.conv_sc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.conv_sc.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for blocks.0.0.bn1.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn1.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn1.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.0.0.bn1.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.0.0.bn2.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn2.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.0.0.bn2.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.0.0.bn2.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.1.0.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\n\tsize mismatch for blocks.1.0.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.conv1.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for blocks.1.0.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for blocks.1.0.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.conv2.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for blocks.1.0.conv_sc.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for blocks.1.0.conv_sc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.conv_sc.u0: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for blocks.1.0.bn1.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.1.0.bn1.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.1.0.bn1.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.1.0.bn1.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for blocks.1.0.bn2.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.bn2.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.1.0.bn2.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.1.0.bn2.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for blocks.2.0.conv_sc.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for blocks.2.0.bn1.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.2.0.bn1.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.2.0.bn1.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.2.0.bn1.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for blocks.2.0.bn2.gain.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for blocks.2.0.bn2.bias.weight: copying a param with shape torch.Size([100, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for output_layer.0.gain: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.0.stored_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.0.stored_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.2.weight: copying a param with shape torch.Size([3, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 64, 3, 3])."
     ]
    }
   ],
   "source": [
    "G = Generator()\n",
    "# D = Discriminator()\n",
    "\n",
    "print(os.getcwd())\n",
    "G.load_state_dict(torch.load('../Biggan_result/weights/Twin_AC_AC_weight1.0_BigGAN_C100_seed0_Gch64_Dch64_bs100_nDs2_Glr2.0e-04_Dlr2.0e-04_Gnlrelu_Dnlrelu_GinitN02_DinitN02_ema/G_ema.pth'), strict=strict)\n",
    "# D.load_state_dict(torch.load('../Biggan_result/weights/Twin_AC_AC_weight1.0_BigGAN_C100_seed0_Gch64_Dch64_bs100_nDs2_Glr2.0e-04_Dlr2.0e-04_Gnlrelu_Dnlrelu_GinitN02_DinitN02_ema/D.pth'), strict=strict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "base2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
